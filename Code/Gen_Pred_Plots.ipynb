{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle;\n",
    "import numpy as np;\n",
    "from numpy.linalg import pinv;\n",
    "from numpy.polynomial.legendre import legvander;\n",
    "import tensorflow as tf\n",
    "\n",
    "import control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt;\n",
    "matplotlib.rcParams.update({'font.size':20}) # default font size on (legible) figures\n",
    "# colors =[[ 0.68627453,  0.12156863,  0.16470589],\n",
    "#        [ 0.96862745,  0.84705883,  0.40000001],\n",
    "#        [ 0.83137256,  0.53333336,  0.6156863 ],\n",
    "#        [ 0.03529412,  0.01960784,  0.14509805],\n",
    "#        [ 0.90980393,  0.59607846,  0.78039217],\n",
    "#        [ 0.69803923,  0.87843138,  0.72941178],\n",
    "#        [ 0.20784314,  0.81568629,  0.89411765]];\n",
    "\n",
    "colors = [[255,158,74],[237,102,93],[173,139,201],\\\n",
    "          [114,158,206],[103,191,92],[237,151,202],\\\n",
    "          [205,204,93],[168,120,110],[162,162,162],[109,204,218]]\n",
    "\n",
    "colors = np.asarray(colors)/255; # defines a color palette \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_data(file_path,has_control,has_output):\n",
    "        '''load pickle data file for deep Koopman dynamic mode decomposition. \n",
    "        Args: \n",
    "           file_path: \n",
    "\n",
    "        '''     \n",
    "        file_obj = open(file_path,'rb');\n",
    "        output_vec = pickle.load(file_obj);\n",
    "        print(type(output_vec))\n",
    "        Xp = None;\n",
    "        Xf = None;\n",
    "        Yp = None;\n",
    "        Yf = None;\n",
    "        Up = None;\n",
    "        \n",
    "        if type(output_vec) == list:\n",
    "          Xp = output_vec[0]; # list of baseline observables, len(Yp) = (n_samps-1) \n",
    "          Xf = output_vec[1]; # list of baseline observables, len(Yf) = (n_samps-1)\n",
    "          if has_control:\n",
    "            Up = output_vec[2];\n",
    "          if has_output:\n",
    "            Yp = output_vec[3];\n",
    "            Yf = output_vec[4]; \n",
    "            #print(Up[0:10]\n",
    "          if len(Xp)<2:\n",
    "            print(\"Warning: the time-series data provided has no more than 2 points.\")\n",
    "            \n",
    "        if type(output_vec) == dict:\n",
    "          Xp = output_vec['Xp'];\n",
    "          Xf = output_vec['Xf'];\n",
    "          Yp = output_vec['Yp'];\n",
    "          Yf = output_vec['Yf'];\n",
    "          if has_control:\n",
    "            Up = output_vec['Up'];\n",
    "          if has_output:\n",
    "            Yp = output_vec['Yp'];\n",
    "            Yf = output_vec['Yf']; \n",
    "          if len(Xp)<2:\n",
    "            print(\"Warning: the time-series data provided has no more than 2 points.\")\n",
    "    \n",
    "          \n",
    "        #print(\"DEBUG:\") + repr(len(output_vec));\n",
    "          \n",
    "\n",
    "        X_whole = [None]*(len(Xp)+1);\n",
    "        \n",
    "        for i in range(0,len(Xp)+1):\n",
    "            if i == len(Xp):\n",
    "                X_whole[i] = Xf[i-1];\n",
    "            else:\n",
    "                X_whole[i] = Xp[i];\n",
    "\n",
    "        X_whole = np.asarray(X_whole);\n",
    "        \n",
    "        return np.asarray(Xp),np.asarray(Xf),X_whole,Up,Yp,Yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't load save_path when it is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a918f02c3d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'incoherent_ff_loop.pickle.ckpt.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpsiyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'psiyp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't load save_path when it is None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0mcheckpoint_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't load save_path when it is None."
     ]
    }
   ],
   "source": [
    "with_control = 1;\n",
    "\n",
    "sess = tf.InteractiveSession();\n",
    "\n",
    "saver = tf.train.import_meta_graph('incoherent_ff_loop.pickle.ckpt.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./'));\n",
    "\n",
    "psiyp = tf.get_collection('psiyp')[0];\n",
    "psiyf = tf.get_collection('psiyf')[0];\n",
    "\n",
    "if with_control:\n",
    "    forward_prediction_control = tf.get_collection('forward_prediction_control')[0];\n",
    "else:\n",
    "    forward_prediction = tf.get_collection('forward_prediction')[0];\n",
    "    \n",
    "yp_feed = tf.get_collection('yp_feed')[0];\n",
    "yf_feed = tf.get_collection('yf_feed')[0];\n",
    "Kx = tf.get_collection('Kx')[0];\n",
    "Kx_num = sess.run(Kx);\n",
    "A = np.transpose(Kx_num); # Kx_num and Ku_num were defined using row multi. \n",
    "\n",
    "if with_control:\n",
    "    psiu = tf.get_collection('psiu')[0];\n",
    "    u_control = tf.get_collection('u_control')[0];\n",
    "    Ku = tf.get_collection('Ku')[0];\n",
    "    Ku_num = sess.run(Ku);\n",
    "    B = np.transpose(Ku_num);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d,v] = np.linalg.eig(Kx_num)\n",
    "# print(np.max(np.abs(d)))\n",
    "# print(np.real(v[:,np.argmax(np.abs(d))]))\n",
    "\n",
    "plt.figure();\n",
    "plt.plot(np.real(d),np.imag(d),'.');\n",
    "plt.xlabel('Real(eigvals)')\n",
    "plt.ylabel('Imag(eigvals)')\n",
    "\n",
    "import control\n",
    "\n",
    "sys = control.ss(Kx_num,B,np.eye(Kx_num.shape[0]),np.zeros( ( A.shape[0],B.shape[1]) ))\n",
    "# control.dlyap(Kx_num,np.dot(B,B.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = 'koopman_data/'\n",
    "data_suffix = 'incoherent_ff_loop.pickle';\n",
    "data_file = data_directory + data_suffix;\n",
    "Yp,Yf,Ywhole,u_control_all_training,fake_outputp,fake_outputf = load_pickle_data(data_file,1,0);\n",
    "with_control = 1;\n",
    "Y_p_old = Yp\n",
    "\n",
    "num_trains = len(Yp)*5.0/10;\n",
    "train_indices = range(0,np.int(num_trains),1);#np.random.randint(0,len(Yp),num_trains)\n",
    "test_indices = range(np.int(num_trains),len(Yp),1);#np.random.randint(0,len(Yp),len(Yp)-num_trains);\n",
    "\n",
    "num_bas_obs = len(Yp[0]);\n",
    "print(\"[INFO]: Number of training datapoints \" + repr(num_trains));\n",
    "print(\"[INFO]: Number of state components: \" + repr(len(Yp[0])));\n",
    "\n",
    "\n",
    "if with_control:\n",
    "    U_test = u_control_all_training[test_indices,:];\n",
    "    U_train = u_control_all_training[train_indices,:];\n",
    "    n_inputs_control = u_control_all_training.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  N-Step Prediction Visualization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # # - - - n-step Prediction Error Analysis - - - # # # \n",
    "\n",
    "for traj in [1]:#list(np.arange(1,45,2)):  \n",
    "    n_points_pred = 99 #int(len(Y_p_old) - test_indices[0]-1);\n",
    "\n",
    "    init_index = int(test_indices[0]+traj*99);\n",
    "    Yf_final_test_stack_nn = np.asarray(Y_p_old).T[:,init_index:(init_index+1)+n_points_pred]\n",
    "    Ycurr = np.asarray(Y_p_old).T[:,init_index]\n",
    "    Ycurr = np.transpose(Ycurr);\n",
    "    if with_control:\n",
    "        Uf_final_test_stack_nn = np.asarray(u_control_all_training).T[:,init_index:(init_index+1)+n_points_pred]\n",
    "\n",
    "    #Reshape for tensorflow, which operates using row multiplication. \n",
    "    Ycurr = Ycurr.reshape(1,num_bas_obs);\n",
    "    psiyp_Ycurr = psiyp.eval(feed_dict={yp_feed:Ycurr});\n",
    "    psiyf_Ycurr = psiyf.eval(feed_dict={yf_feed:Ycurr});\n",
    "\n",
    "\n",
    "    ## Define a growing list of vector valued observables that is the forward prediction of the Yf snapshot matrix, initiated from an initial condition in Yp_final_test.   \n",
    "    Yf_final_test_ep_nn = [];  #Variable to store final Test Predictions of Yforwrad snapshots, using an extended or multi-step prediction approach on the deepDMD basis.  \n",
    "    Yf_final_test_ep_nn.append(psiyp_Ycurr.tolist()[0][0:num_bas_obs]); # append the initial seed state value.\n",
    "\n",
    "    for i in range(0,n_points_pred):\n",
    "      if with_control:\n",
    "        if len(U_test[i,:])==1:\n",
    "          U_temp_mat = np.reshape(Uf_final_test_stack_nn[i,:],(1,1));\n",
    "          psiyp_Ycurr = sess.run(forward_prediction_control, feed_dict={yp_feed:psiyp_Ycurr[:,0:num_bas_obs],u_control:U_temp_mat});#\n",
    "        else:\n",
    "          U_temp_mat = np.reshape(Uf_final_test_stack_nn.T[i,:],(1,n_inputs_control));\n",
    "          psiyp_Ycurr = sess.run(forward_prediction_control, feed_dict={yp_feed:psiyp_Ycurr[:,0:num_bas_obs],u_control:U_temp_mat});# \n",
    "      else:\n",
    "        psiyp_Ycurr = sess.run(forward_prediction,feed_dict={yp_feed:psiyp_Ycurr[:,0:num_bas_obs]});\n",
    "\n",
    "      Yout = psiyp_Ycurr.tolist()[0][0:num_bas_obs];\n",
    "      Yf_final_test_ep_nn.append(Yout);\n",
    "\n",
    "\n",
    "    Yf_final_test_ep_nn = np.asarray(Yf_final_test_ep_nn);\n",
    "    Yf_final_test_ep_nn = np.transpose(Yf_final_test_ep_nn);\n",
    "\n",
    "    prediction_error = np.linalg.norm(Yf_final_test_stack_nn-Yf_final_test_ep_nn,ord='fro')/np.linalg.norm(Yf_final_test_stack_nn,ord='fro');\n",
    "    print('%s%f' % ('[RESULT] n-step prediction error for trajectory ' + str(traj) +' : ',prediction_error));\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.rcParams.update({'font.size':20})\n",
    "\n",
    "    plt.figure(figsize=(9,6))\n",
    "    ### Make a Prediction Plot\n",
    "    x_range = np.arange(0,n_points_pred,1)\n",
    "    #x_range = np.arange(0,Yf_final_test_stack_nn.shape[1],1);\n",
    "    for i in range(0,num_bas_obs):\n",
    "        g = plt.plot(x_range,Yf_final_test_stack_nn[i,0:len(x_range)],'.',color=colors[i,:],ms=8);\n",
    "        h = plt.plot(x_range,Yf_final_test_ep_nn[i,0:len(x_range)],color=colors[i,:],linewidth=3,linestyle='--');\n",
    "    axes = plt.gca();\n",
    "    # axes.spines['right'].set_visible(False)\n",
    "    # axes.spines['top'].set_visible(False)\n",
    "    \n",
    "#     plt.title('trajectory ' + str(traj))\n",
    "\n",
    "    # plt.legend(loc='best');\n",
    "    # plt.legend((h[0],g[0]),('Predicted','Truth'),loc='best');\n",
    "    # leg = axes.get_legend()\n",
    "    # leg.legendHandles[0].set_color('black')\n",
    "    # leg.legendHandles[1].set_color('black')\n",
    "    plt.xlabel('Time');\n",
    "    #plt.ylim([0,3.0])\n",
    "    # fig = plt.gcf();\n",
    "\n",
    "    import matplotlib.lines as mlines\n",
    "    black_line = mlines.Line2D([], [], color='black',linestyle='--',label='Predicted')\n",
    "    black_dot = mlines.Line2D([], [],linestyle='',color='black',marker='.',label='Truth')\n",
    "    plt.legend(handles=[black_line,black_dot]);\n",
    "\n",
    "    import os\n",
    "    filename = 'incoherent_ff_loop_final_nstep_prediction.pdf'\n",
    "    path = '/users/aqib/desktop/ucsb/research/bccl/koopman_ss_prog/code'\n",
    "    fullpath = os.path.join(path, filename)\n",
    "    # target_file = data_suffix.replace('.pickle','')+'final_nstep_prediction.pdf';\n",
    "    target_file = fullpath\n",
    "    plt.savefig(target_file);\n",
    "    # plt.show();\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataDump = {'Kx':Kx_num,'Ku':Ku_num}\n",
    "# filename = 'incoherent_ff_loop_deepDMD_model.pickle'\n",
    "# path = '/users/aqib/desktop/ucsb/research/bccl/koopman_ss_prog/code'\n",
    "# fullpath = os.path.join(path, filename)\n",
    "# # pickle.dump( data, open( 'filename.picle', 'wb' ) )\n",
    "# # data = pickle.load( open( 'filename.pickle', 'rb' ) )\n",
    "# pickle.dump(dataDump,open(fullpath,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
